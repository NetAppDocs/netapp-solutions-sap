---
sidebar: sidebar
permalink: backup/hana-sc-vmfs-asar2-sc-restore.html
keywords: SAP HANA, VMware, SnapCenter, backup and recovery
summary: 
---

= Restore and recovery operations

:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ../media/

With virtual resources stored on VMFS/VMDKâ€™s a SnapCenter restore operations are always done by a clone, mount, copy operation.

[arabic]
. SnapCenter creates a storage clone based on the selected Snapshot
. SnapCenter mounts the LUN as a new datastore to the ESX host
. SnapCenter adds the VMDK within the datastore as a new disk to the HANA VM
. SnapCenter mounts the new disk to the Linux OS
. SnapCenter copies the data from the new disk back to the original location
. When the copy operation is finished all above resource are removed again
. SnapCenter executes recovery of the HANA system database
. SnapCenter executes recovery of the HANA tenant database

The overall runtime of the restore operation is dependent on the database size and the throughput of the FC connection between the storage clusters and the ESX hosts. In our lab setup with an initial HANA installation the runtime has been around 12 minutes.

image:sc-hana-asrr2-vmfs-image23.png["Figure demonstrating the content being discussed"]

image:sc-hana-asrr2-vmfs-image24.png["Figure demonstrating the content being discussed"]

While the restore and recovery operation is running, you can see a new cloned storage unit.

image:sc-hana-asrr2-vmfs-image25.png["Figure demonstrating the content being discussed"]

The new LUN (datastore) based on the cloned storage unit gets attached to the ESX cluster.

image:sc-hana-asrr2-vmfs-image26.png["Figure demonstrating the content being discussed"]

The VMDK within the datastore gets mapped to the target HANA VM and mounted to the HANA system.

....
hana-8:~ # df -h

Filesystem Size Used Avail Use% Mounted on
/dev/mapper/system-root 60G 5.3G 54G 9% /
devtmpfs 4.0M 8.0K 4.0M 1% /dev
tmpfs 49G 0 49G 0% /dev/shm
efivarfs 256K 57K 195K 23% /sys/firmware/efi/efivars
tmpfs 13G 26M 13G 1% /run
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup-dev-early.service
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-sysctl.service
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-sysusers.service
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup-dev.service
/dev/mapper/system-root 60G 5.3G 54G 9% /.snapshots
/dev/mapper/system-root 60G 5.3G 54G 9% /boot/grub2/i386-pc
/dev/mapper/system-root 60G 5.3G 54G 9% /boot/grub2/x86++_++64-efi
/dev/mapper/system-root 60G 5.3G 54G 9% /home
/dev/mapper/system-root 60G 5.3G 54G 9% /opt
/dev/mapper/system-root 60G 5.3G 54G 9% /root
/dev/mapper/system-root 60G 5.3G 54G 9% /srv
/dev/mapper/system-root 60G 5.3G 54G 9% /usr/local
/dev/mapper/system-root 60G 5.3G 54G 9% /tmp
/dev/mapper/system-root 60G 5.3G 54G 9% /var
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-vconsole-setup.service
/dev/sdc 95G 8.9G 87G 10% /hana/log/VFS/mnt00001
/dev/sdb 95G 7.6G 88G 8% /hana/data/VFS/mnt00001
/dev/sdd 95G 15G 81G 16% /hana/shared
/dev/sda1 253M 5.9M 247M 3% /boot/efi
tmpfs 1.0M 0 1.0M 0% /run/credentials/systemd-tmpfiles-setup.service
192.168.175.86:/sapcc++_++share 1.4T 858G 568G 61% /mnt/sapcc-share
tmpfs 6.3G 72K 6.3G 1% /run/user/464
tmpfs 1.0M 0 1.0M 0% /run/credentials/getty@tty1.service
tmpfs 6.3G 52K 6.3G 1% /run/user/0
/dev/sde 95G 9.2G 86G 10% /var/opt/snapcenter/scu/clones/hana_data_VFS_mnt00001_142592_scu_clone_1

hana-8:~ #
....

image:sc-hana-asrr2-vmfs-image27.png["Figure demonstrating the content being discussed"]

